# ğŸ“š Conversational RAG with PDF Uploads and Chat History

An interactive Streamlit application that lets you **upload PDFs and chat with their content** using a modern **RAG (Retrieval-Augmented Generation)** architecture. Powered by **Groqâ€™s blazing-fast LLMs**, **HuggingFace embeddings**, and **LangChain**, this tool brings intelligent, document-aware conversations to life.

---

## ğŸš€ Features

- ğŸ“„ **Upload PDFs** â€“ Drop in any PDF and chat with its contents.
- ğŸ§  **Conversational Memory** â€“ Maintains chat history using LangChainâ€™s memory module.
- âš¡ **Groq-Powered LLM** â€“ Leverages `Gemma 2 9B-It` via Groq for ultra-fast and fluent answers.
- ğŸ” **Smart Retrieval** â€“ Semantic chunk retrieval using `all-MiniLM-L6-v2` embeddings.
- ğŸ› ï¸ **LangChain Integration** â€“ Modular and flexible chain architecture using LangChain.
- ğŸ’¡ **Perfect for Research, Study, and Knowledge Mining**.

---

## ğŸ§‘â€ğŸ’» Tech Stack

| Component        | Description                                  |
|------------------|----------------------------------------------|
| Frontend         | [Streamlit](https://streamlit.io)            |
| LLM              | [Groq](https://groq.com) - `Gemma 2 9B-It`   |
| Embeddings       | HuggingFace `all-MiniLM-L6-v2`               |
| Vector Store     | [Chroma](https://www.trychroma.com/)         |
| PDF Loader       | LangChainâ€™s `PyPDFLoader`                    |
| Chain Framework  | [LangChain](https://www.langchain.com)       |
| Environment Vars | `python-dotenv`                              |

---

## ğŸ§  How It Works

1. **PDF Upload** â†’ You select a `.pdf` file.
2. **Text Extraction** â†’ PDF content is extracted and split into chunks.
3. **Embeddings** â†’ Chunks are embedded with `all-MiniLM-L6-v2`.
4. **Vector Store** â†’ Chunks are stored in Chroma for fast semantic search.
5. **LLM Q&A** â†’ Groq's Gemma2-9B-It answers your question using relevant chunks.
6. **Memory** â†’ Past messages are remembered for contextual understanding.

---

## âš™ï¸ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/your-username/conversational-pdf-rag.git
cd conversational-pdf-rag
```
2. Install dependencies
```bash
Copy code
pip install -r requirements.txt
```
3. Create a .env file

```bash
HUGGINGFACE_API_KEY=your_huggingface_api_key
```
The Groq API key is entered inside the app interface (for security).

4. Run the Streamlit app
```bash
Copy code
streamlit run app.py
```


# ğŸ“¸ Screenshots
---
---

# ğŸ—‚ Example Project Structure
```bash
Copy code
conversational-pdf-rag/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ README.md
â””â”€â”€ .streamlit/
```
# ğŸ“„ License
MIT License. Feel free to fork, use, and modify.

# ğŸ™‹â€â™‚ï¸ Contributions
Pull requests and ideas welcome! If you find this useful, â­ï¸ star the repo and share it.

